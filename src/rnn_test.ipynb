{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[38.7364443 -9.1407651]\n",
      " [38.7356124 -9.1396516]\n",
      " [38.7368552 -9.1396499]]\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Bidirectional\n",
    "\n",
    "\n",
    "USER_ID = 353\n",
    "PATH_DATA = '../data/user_sequences/'\n",
    "EXTENSION_TEXT = '.txt'\n",
    "PATH_USER_DATA = PATH_DATA + f'user_{USER_ID}_sequence' + EXTENSION_TEXT\n",
    "\n",
    "data = pd.read_csv(PATH_USER_DATA, header=None)\n",
    "data = data.to_numpy()[:,1:]  # Discard weekday, just for now\n",
    "print(data[0:3,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 2)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "X = data[0:-1,:]\n",
    "y = data[1:,:]\n",
    "\n",
    "X_train = X[0:190,:]\n",
    "y_train = y[0:190,:]\n",
    "\n",
    "X_test = X[190:,:]\n",
    "y_test = y[190:,:]\n",
    "\n",
    "sequence_length = 3\n",
    "train_generator = TimeseriesGenerator(X_train, y_train, length=sequence_length, batch_size=16)\n",
    "test_generator = TimeseriesGenerator(X_test, y_test, length=3, batch_size=4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "12/12 [==============================] - 3s 5ms/step - loss: 771.3391\n",
      "Epoch 2/70\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 709.6717\n",
      "Epoch 3/70\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 618.7500\n",
      "Epoch 4/70\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 525.5399\n",
      "Epoch 5/70\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 458.6472\n",
      "Epoch 6/70\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 408.9746\n",
      "Epoch 7/70\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 372.7759\n",
      "Epoch 8/70\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 344.7881\n",
      "Epoch 9/70\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 322.0008\n",
      "Epoch 10/70\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 301.5216\n",
      "Epoch 11/70\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 283.4585\n",
      "Epoch 12/70\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 266.4388\n",
      "Epoch 13/70\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 251.2548\n",
      "Epoch 14/70\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 236.8310\n",
      "Epoch 15/70\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 223.5691\n",
      "Epoch 16/70\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 211.0396\n",
      "Epoch 17/70\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 199.1895\n",
      "Epoch 18/70\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 188.0738\n",
      "Epoch 19/70\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 177.6362\n",
      "Epoch 20/70\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 167.5194\n",
      "Epoch 21/70\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 158.0074\n",
      "Epoch 22/70\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 148.9710\n",
      "Epoch 23/70\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 140.4283\n",
      "Epoch 24/70\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 132.3315\n",
      "Epoch 25/70\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 124.5527\n",
      "Epoch 26/70\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 117.2439\n",
      "Epoch 27/70\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 110.3277\n",
      "Epoch 28/70\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 103.6136\n",
      "Epoch 29/70\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 97.2695\n",
      "Epoch 30/70\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 91.3179\n",
      "Epoch 31/70\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 85.6844\n",
      "Epoch 32/70\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 80.3892\n",
      "Epoch 33/70\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 75.3132\n",
      "Epoch 34/70\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 70.4762\n",
      "Epoch 35/70\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 65.9099\n",
      "Epoch 36/70\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 61.6391\n",
      "Epoch 37/70\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 57.5058\n",
      "Epoch 38/70\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 53.6558\n",
      "Epoch 39/70\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 50.0554\n",
      "Epoch 40/70\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 46.6152\n",
      "Epoch 41/70\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 43.4520\n",
      "Epoch 42/70\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 40.4126\n",
      "Epoch 43/70\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 37.5667\n",
      "Epoch 44/70\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 34.8462\n",
      "Epoch 45/70\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.3206\n",
      "Epoch 46/70\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 29.9522\n",
      "Epoch 47/70\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 27.7762\n",
      "Epoch 48/70\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 25.6777\n",
      "Epoch 49/70\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 23.7749\n",
      "Epoch 50/70\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 21.9702\n",
      "Epoch 51/70\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 20.2556\n",
      "Epoch 52/70\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 18.6601\n",
      "Epoch 53/70\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 17.2248\n",
      "Epoch 54/70\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 15.8210\n",
      "Epoch 55/70\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 14.5776\n",
      "Epoch 56/70\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 13.3840\n",
      "Epoch 57/70\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 12.2691\n",
      "Epoch 58/70\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 11.2447\n",
      "Epoch 59/70\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 10.3061\n",
      "Epoch 60/70\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9.4251\n",
      "Epoch 61/70\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 8.6250\n",
      "Epoch 62/70\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 7.8754\n",
      "Epoch 63/70\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 7.1808\n",
      "Epoch 64/70\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 6.5477\n",
      "Epoch 65/70\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5.9705\n",
      "Epoch 66/70\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5.4193\n",
      "Epoch 67/70\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 4.9338\n",
      "Epoch 68/70\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 4.4728\n",
      "Epoch 69/70\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 4.0578\n",
      "Epoch 70/70\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 3.6757\n"
     ]
    }
   ],
   "source": [
    "lstm_model = Sequential()\n",
    "lstm_model.add(LSTM(50, input_shape=(sequence_length, 2), return_sequences=True))\n",
    "lstm_model.add(LSTM(50))\n",
    "lstm_model.add(Dense(2))\n",
    "lstm_model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "epochs = 70\n",
    "lstm_history = lstm_model.fit(train_generator, epochs=epochs, verbose=1, batch_size=4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.475886106491089\n"
     ]
    }
   ],
   "source": [
    "lstm_score = lstm_model.evaluate(test_generator, verbose=0)\n",
    "\n",
    "print(lstm_score)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
